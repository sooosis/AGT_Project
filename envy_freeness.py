# -*- coding: utf-8 -*-
"""envy_freeness.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lfw27KdV5kSDjoKpF8Yq4xJ781wazL0X
"""

import random, math
import matplotlib.pyplot as plt
import numpy as np

def create_game_matrix(n,m,t):
  
  l = []
  g = []
  for i in range(0,m):
    l.append(random.uniform(0,1))
  for i in range(0,n):
    if t == 1:
      g.append(random.sample(l, k=len(l)))
    elif t == 2:
      temp=[]
      for i in range(0,m):
        temp.append(random.uniform(0,1))
      g.append(temp)
    else:
      g.append(l)
    

  
  return np.array(g)

def sampling(dist,m):

  s = 0
  sample_dist = []
  mini = min(dist)
  for i in range(0,m):
    dist[i] = dist[i] - mini
    s += np.exp(dist[i])
  
  for i in range(0,m):
    sample_dist.append(np.exp(dist[i])/s)

  return(np.random.choice( np.arange(0, m), p=sample_dist))

#envy freeness
T = 1000
eta = np.sqrt(1/T)
n = 4
m = 4
beta = 1/2000
alpha = 0


dist=[]
envy = []
rw = [0]*n

ne_dist=[]
ne_envy= []
ne_rw = [0]*n

tef=[]
ne_tef=[]
time=[]

for i in range(0,n):
  dist.append([0] * m)
  ne_dist.append([0] * m)

  envy.append([0]*n)
  ne_envy.append([0]*n)
  


game = create_game_matrix(n,m,20)
print(game)

for t in range(T):

  time.append(t)

  actions = []
  ne_actions = []

  rewards = [0]*n
  ne_rewards = [0]*n

  for i in range(0,n):
    actions.append(sampling(dist[i],m))
    ne_actions.append(sampling(ne_dist[i],m))

  
  for i in range(0,n):

    if actions.count(actions[i]) > 1:
      rewards[i] = alpha
      #rw[i] += alpha
    else:
      rewards[i] = game[i][actions[i]]
      rw[i] += game[i][actions[i]]
      
      for j in range(0,n):
        if i != j:
          envy[j][i] += game[j][actions[i]]

    envy[i][i] = rw[i]
    
    
    
    if ne_actions.count(ne_actions[i]) > 1:
      ne_rewards[i] = alpha
      #ne_rw[i] += alpha
    else:
      ne_rewards[i] = game[i][ne_actions[i]]
      ne_rw[i] += game[i][ne_actions[i]]
      
      for j in range(0,n):
        if i != j:
          ne_envy[j][i] += game[j][ne_actions[i]]

    ne_envy[i][i] = ne_rw[i]
  
  
  ef = 0
  ne_ef = 0
  mi = min(rw)

  for i in range(0,n):
    ef = max(ef,max(envy[i])-rw[i])
    ne_ef = max(ne_ef,max(ne_envy[i])-ne_rw[i])
  tef.append(ef)
  ne_tef.append(ne_ef)
  
  for i in range(0,n):
    for j in range(0,m):
      if(j == ne_actions[i]):
        dist[i][j] += eta*(1 - ( 1-(rewards[i]- beta*(rw[i]-mi)*(rw[i]-mi))/ (np.exp(dist[i][j])/np.sum(np.exp(dist[i]))) )     )
      else:
        dist[i][j] += eta
  
  for i in range(0,n):
    for j in range(0,m):
      if(j == ne_actions[i]):
        ne_dist[i][j] += eta*(1 - (1-ne_rewards[i])/(np.exp(ne_dist[i][j])/np.sum(np.exp(ne_dist[i]))))
      else:
        ne_dist[i][j] += eta
  #print(rw[0],rw[1])
  # print(envy)

  


# for i in range(0,n):
#   print("dist of Player",i, np.exp(dist[i]) / np.sum(np.exp(dist[i])), "ne dist of Player",i, np.exp(ne_dist[i]) / np.sum(np.exp(ne_dist[i])), rw[i], ne_rw[i])

ef = 1
ne_ef = 1

for i in range(0,n):
  ef = min(ef,rw[i]/max(envy[i]))
  ne_ef = min(ne_ef,ne_rw[i]/max(ne_envy[i]))
print(envy)

print(max(rw)-min(rw))
print(max(ne_rw)-min(ne_rw))
print(ef,ne_ef)

plt.plot(time,tef,color='b')
plt.plot(time,ne_tef,color='y')